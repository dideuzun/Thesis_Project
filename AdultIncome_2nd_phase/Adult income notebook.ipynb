{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe from a csv file\n",
    "df = pd.read_csv('CensusAdultIncome.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- workclass: A categorical feature representing the type of income, such as private, self-employment, and government employment. Some missing values present.\n",
    "- fnlwgt: An integer feature with no description provided. No missing values.\n",
    "- education: A categorical feature representing the level of education \n",
    "- education-num: An integer feature representing the numerical encoding of **education** level.\n",
    "- occupation: A categorical feature representing the type of occupation, such as managerial, technical, and service-related occupations. Some missing values present.\n",
    "- native-country: A categorical feature representing the country of origin, including various countries such as the United States, Canada, and India. Some missing values present.\n",
    "- income: The target variable, a binary feature representing income level, with categories >50K and <=50K. No missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cleaning the target variable and making it binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dideu\\AppData\\Local\\Temp\\ipykernel_21648\\3457457334.py:2: FutureWarning: The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n",
      "  df['income'] = df['income'].str.replace('.', '')\n"
     ]
    }
   ],
   "source": [
    "#Target value has values with dots, therefore 4 catagories\n",
    "df['income'] = df['income'].str.replace('.', '')\n",
    "\n",
    "# Replace the values in the target column with string '0' and '1'.\n",
    "df['income'] = df['income'].str.replace('<=50K', '0')  \n",
    "df['income'] = df['income'].str.replace('>50K', '1')   \n",
    "\n",
    "# Convert to integer\n",
    "df['income'] = df['income'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  int32 \n",
      "dtypes: int32(1), int64(6), object(8)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print count and percentage of classes variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " 0    37155\n",
      "1    11687\n",
      "Name: income, dtype: int64 \n",
      "\n",
      "Percentage of each class: \n",
      " 0    76.071823\n",
      "1    23.928177\n",
      "Name: income, dtype: float64\n",
      "\n",
      "Total number of rows:  48842\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts of unique values in the 'class' column \n",
    "class_counts = df['income'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each unique value in the 'class' column by dividing 'class_counts' by its sum and then multiplying by 100.\n",
    "class_percentages = class_counts / class_counts.sum() * 100\n",
    "\n",
    "print('Class counts:\\n' ,class_counts, '\\n')\n",
    "print('Percentage of each class: \\n' ,class_percentages)\n",
    "print('\\nTotal number of rows: ', df.shape[0])\n",
    "\n",
    "# Saving this for future use\n",
    "a = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some values are like '?'. Replacing them as NaN \n",
    "df[df == '?'] = np.nan\n",
    "# Dropping the rows with NaN values in  'workclass', 'occupation', 'native-country' for the test dataset\n",
    "df.dropna(subset=['workclass', 'occupation', 'native-country'], inplace=True)\n",
    "df.dropna( inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking wheter Education and Education-number are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS-grad         14783\n",
      "Some-college     9899\n",
      "Bachelors        7570\n",
      "Masters          2514\n",
      "Assoc-voc        1959\n",
      "Name: education, dtype: int64\n",
      "\n",
      "9     14783\n",
      "10     9899\n",
      "13     7570\n",
      "14     2514\n",
      "11     1959\n",
      "Name: education-num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['education'].value_counts().head())\n",
    "print()\n",
    "print(df['education-num'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From X set, education column is dropped as it is same with Education-num, which is already in numerical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education-num      marital-status  \\\n",
       "0   39         State-gov   77516             13       Never-married   \n",
       "1   50  Self-emp-not-inc   83311             13  Married-civ-spouse   \n",
       "2   38           Private  215646              9            Divorced   \n",
       "3   53           Private  234721              7  Married-civ-spouse   \n",
       "4   28           Private  338409             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week native-country  income  \n",
       "0             0              40  United-States       0  \n",
       "1             0              13  United-States       0  \n",
       "2             0              40  United-States       0  \n",
       "3             0              40  United-States       0  \n",
       "4             0              40           Cuba       0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count and percentage of Target classes values after droping NaN values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " 0    34014\n",
      "1    11208\n",
      "Name: income, dtype: int64 \n",
      "\n",
      "Percentage of each class: \n",
      " 0    75.215603\n",
      "1    24.784397\n",
      "Name: income, dtype: float64\n",
      "\n",
      "Number of rows after dropping NaN:  45222\n",
      "number of rows dropped:  3620\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts of unique values in the 'class' column of 'df_class_feature' and store it in 'class_counts'.\n",
    "class_counts = df['income'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each unique value in the 'class' column by dividing 'class_counts' by its sum and then multiplying by 100.\n",
    "class_percentages = class_counts / class_counts.sum() * 100\n",
    "\n",
    "print('Class counts:\\n' ,class_counts, '\\n')\n",
    "print('Percentage of each class: \\n' ,class_percentages)\n",
    "\n",
    "b = df.shape[0]\n",
    "print('\\nNumber of rows after dropping NaN: ', b)\n",
    "print('number of rows dropped: ', a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split data into separate fitting and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y sets.income is the target variable and native country dropped because it has 41 unique values and occupation is very similar too workclass.\n",
    "X = df.drop(['income', 'native-country', 'occupation'], axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into fitting data (60%) and test set (40%), the reason I chose 60 to 40 split is to have a bigger test set. I did some experiments with other ratios such as 70 to 30 and 80 to 20 and the model performance metrics were almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit, X_test, y_fit, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The percentage of each class in the target variable for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined a function to calculate  and print the percentage of each class in the target variable\n",
    "def calculate_class_percentage(y):\n",
    "    class_percentage = {}\n",
    "    total_samples = len(y)\n",
    "    unique_classes = set(y)\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        class_count = sum(y == cls)\n",
    "        percentage = (class_count / total_samples) * 100\n",
    "        class_percentage[cls] = percentage\n",
    "    \n",
    "    return class_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit set class percentages:\n",
      "{0: 75.25522426565438, 1: 24.74477573434563}\n",
      "\n",
      "Test set class percentages:\n",
      "{0: 75.15617225938416, 1: 24.843827740615843}\n",
      "\n",
      " Number of rows of X fit 27133 \n",
      " Number of rows of X test 18089 \n",
      " Number of rows of Y fit 27133 \n",
      " Number of rows of y test 18089\n"
     ]
    }
   ],
   "source": [
    "# Calculate class percentages for each dataset\n",
    "fit_class_percentage = calculate_class_percentage(y_fit)\n",
    "test_class_percentage = calculate_class_percentage(y_test)\n",
    "\n",
    "# Print class percentages for each dataset\n",
    "print(\"Fit set class percentages:\")\n",
    "print(fit_class_percentage )\n",
    "print(\"\\nTest set class percentages:\")\n",
    "print(test_class_percentage)\n",
    "print('\\n Number of rows of X fit', X_fit.shape[0], '\\n Number of rows of X test', X_test.shape[0],'\\n Number of rows of Y fit', y_fit.shape[0],'\\n Number of rows of y test', y_test.shape[0],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest and Logistig Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# DiCE imports\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score,  recall_score, precision_score, f1_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RF (X_fit, y_fit, X_test, y_test, model_name):\n",
    "    \n",
    "    # Preprocessing for cataegorical data - OneHotEncoding\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Bundle preprocessing for data\n",
    "    transformations = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical)],\n",
    "        remainder='passthrough')\n",
    "    \n",
    "    # Define the Random Forest model\n",
    "    clf_RF = Pipeline(steps=[('preprocessor', transformations), ('classifier', RandomForestClassifier())])\n",
    "    # Run the random forest model\n",
    "    model_RF = clf_RF.fit(X_fit, y_fit)\n",
    "    # Predict on the test dataset\n",
    "    y_pred_rf = model_RF.predict(X_test)\n",
    "    # Calculate the needed model performance metrics\n",
    "    precision_rf = precision_score(y_test, y_pred_rf)\n",
    "    f1_rf = f1_score(y_test, y_pred_rf)\n",
    "    roc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "\n",
    "    # Saving the model performance metrics\n",
    "    models_rf = [('RF {}'.format(model_name), 0, 0, 0, 0, precision_rf, f1_rf, roc_rf, 0, 0, 0, 0)]\n",
    "    # Saving the model performance metrics in a dataframe\n",
    "    model_perf_metrics_rf = pd.DataFrame(models_rf, columns = ['Model', 'Iteration', 'Sample Size', 'CF Num','Total CF Num', 'Precision (%)', 'F1 (%)', 'AUC(%)', 'F1_average(%)', 'F1_std(%)', 'AUC_average(%)', 'AUC_std(%)'])\n",
    "        \n",
    "    return model_RF, model_perf_metrics_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Logistic Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LR(X_fit, y_fit, X_test, y_test, model_name, i, j , k):\n",
    "    # Preprocessing for categorical data - OneHotEncoding\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Preprocessing for numerical data - StandardScaler\n",
    "    #numerical_transformer = Pipeline(steps=[\n",
    "        #('scaler', StandardScaler())])\n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    transformations = ColumnTransformer(\n",
    "        transformers=[\n",
    "            #('num', numerical_transformer, numerical),  \n",
    "            ('cat', categorical_transformer, categorical)], \n",
    "        remainder='passthrough')\n",
    "\n",
    "    # Define the Logistic Regression model\n",
    "    clf_LR = Pipeline(steps=[('preprocessor', transformations), ('classifier', LogisticRegression(max_iter=1000))])\n",
    "    # Run the Logistic Regression model\n",
    "    model_LR = clf_LR.fit(X_fit, y_fit)\n",
    "    # Predict on the test dataset\n",
    "    y_pred_lr = model_LR.predict(X_test)\n",
    "    # Calculate the needed model performance metrics\n",
    "    precision_lr = precision_score(y_test, y_pred_lr)\n",
    "    f1_lr = f1_score(y_test, y_pred_lr)\n",
    "    roc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "\n",
    "    # Saving the model performance metrics\n",
    "    models_lr = [('LR {}'.format(model_name), k, j, i, i*j, precision_lr, f1_lr, roc_lr, 0, 0, 0, 0)]\n",
    "    # Saving the model performance metrics in a dataframe\n",
    "    model_perf_metric_lr = pd.DataFrame(models_lr, columns = ['Model', 'Iteration', 'Sample Size', 'CF Num','Total CF Num', 'Precision (%)', 'F1 (%)', 'AUC(%)', 'F1_average(%)', 'F1_std(%)', 'AUC_average(%)', 'AUC_std(%)'])\n",
    "\n",
    "    return  model_perf_metric_lr, roc_lr, f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the DICE model. Possible adjustments that can be made are, \n",
    "- which model to use for CF generation, \n",
    "- continuous features, \n",
    "- size of the sample that will be used to create the CFs, \n",
    "- how many CFs to generate per one sample,\n",
    "- which features can vary in the CF generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining DICE model\n",
    "def generate_counterfactuals(X_fit, y_fit, model,continuous_features, sample_size, total_CFs, fea_to_vary, outcome_name):\n",
    "    \n",
    "    # Creating a Data object\n",
    "    d = dice_ml.Data(dataframe=X_fit.assign(income=y_fit), continuous_features=continuous_features, outcome_name=outcome_name)\n",
    "    # Creating a Model object\n",
    "    m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
    "    # Creating the DICE model with data and model object \n",
    "    exp = dice_ml.Dice(d, m, method=\"random\")\n",
    "\n",
    "    # Execution of the DICE model to generate counterfactuals\n",
    "    e1 = exp.generate_counterfactuals(X_fit[0:sample_size], total_CFs=total_CFs, desired_class=\"opposite\", features_to_vary= fea_to_vary)\n",
    "    \n",
    "    # Comment out the below line as CFs needed to be visualized in the notebook\n",
    "    #e1.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "    # Creating a new empty dataframe to store the generated CFs\n",
    "    cf_df = pd.DataFrame()\n",
    "    # For loop to append the counterfactuals of each sample, to a dataframe\n",
    "    for i in range(0, sample_size):\n",
    "        # Saving CFs\n",
    "        xd = e1.cf_examples_list[i].final_cfs_df\n",
    "        # Adding the generated CFs to the empty dataframe\n",
    "        cf_df = pd.concat([cf_df, xd])\n",
    "# If the sample size is reached and the CFs are generated for all the samples, followiing code resets the index of the dataframe and saves the generated CFs as a csv file.\n",
    "    else:\n",
    "        # Resetting the index of the dataframe to not have duplicate index number\n",
    "        cf_df.reset_index(drop=True, inplace=True)\n",
    "        new_start_index = 40000*i + len(cf_df)\n",
    "        cf_df.index += new_start_index \n",
    "        # Saving the generated CFs as a csv file\n",
    "        cf_df.to_csv('cf_df_{}_{}.csv'.format(sample_size, total_CFs))\n",
    "        \n",
    "        # Following code creates X and y fit sets for the generated CFs and returns them for further use.\n",
    "        X_fit_cf = cf_df.drop([outcome_name], axis=1)\n",
    "        y_fit_cf = cf_df[outcome_name]\n",
    "\n",
    "    return X_fit_cf, y_fit_cf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a fuction that runs the RF and LR plus DICE model that generates counterfactuals. \n",
    "#### Then the function saves these CF explanations into a dataframe and trains the LR again with the generated CFs. At the same time, model appends the original fit-set to CF dataset and trains the LR again with the combined version of the datasets. For each model training, LR model function appends the new model performance metrics into a dataframe. Possible adjustments that can be made are, \n",
    "- continuous features, \n",
    "- size of the sample that will be used to create the CFs, \n",
    "- how many CFs to generate per one sample,\n",
    "- how many iterations will be made for each sample_size and CF_number pair,\n",
    "- which features can vary in the CF generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment running function\n",
    "def running_exp(X_fit, y_fit, continuous_features, sample_size_list, total_CFs_list, iteration_num, fea_to_vary, num):\n",
    "    #Running default Random Forest\n",
    "    model_RF, model_perf_metric_rf = run_RF(X_fit, y_fit, X_test, y_test, 'default')\n",
    "    #Running default Logistic Regression\n",
    "    model_perf_metric_lr, auc, f1 = run_LR(X_fit, y_fit, X_test, y_test, 'default', 0 , 0 , 0)\n",
    "\n",
    "    # Merging the default model performance metrics in a dataframe to accommodate new models, and doing it twice to use the second one on only CFs dataset.\n",
    "    model_perf_metrics_merged = model_perf_metric_rf.merge(model_perf_metric_lr, how='outer')\n",
    "    model_perf_metrics_merged_only_for_cfs = model_perf_metric_rf.merge(model_perf_metric_lr, how='outer')\n",
    "\n",
    "    # Loop through different sample sizes\n",
    "    for j in sample_size_list:\n",
    "        # Loop through different total CF numbers\n",
    "        for i in total_CFs_list:\n",
    "            # Initializing empty lists for saving auc and f1 scores for each iteration\n",
    "            total_auc = []\n",
    "            total_f1 = []\n",
    "            total_auc_cf = []\n",
    "            total_f1_cf = []\n",
    "            # Loop through iteration numbers, doing a new experiment for each sample_size and CF_number combination\n",
    "            for k in range(1,iteration_num+1):    \n",
    "                # Generating counterfactuals using the 'generate_counterfactuals' function\n",
    "                X_fit_cf, y_fit_cf = generate_counterfactuals(X_fit, y_fit, model_RF,continuous_features, j, i, fea_to_vary, 'income')\n",
    "                # Concatenating the original dataset with the generated CFs dataset\n",
    "                new_X_fit = pd.concat([X_fit, X_fit_cf])\n",
    "                new_y_fit = pd.concat([y_fit, y_fit_cf])\n",
    "\n",
    "                # Running the Logistic Regression model on the CFs dataset and the dataset with original X_fit plus CFs.\n",
    "                model_perf_metric_lr_only_cf, auc_only_cf, f1_only_cf = run_LR(X_fit_cf, y_fit_cf, X_test, y_test, '_{}_iterations_sample:{}_cf:{}'.format(k, j, i), i , j , k)\n",
    "                model_perf_metric_lr_cf, auc_lr_cf, f1_lr_cf = run_LR(new_X_fit, new_y_fit, X_test, y_test, '_{}_iterations_sample:{}_cf:{}'.format(k, j, i), i , j , k)\n",
    "                \n",
    "                # Appending the auc and f1 scores of each iteration to the lists, doing the same for only CFs set.\n",
    "                total_auc_cf.append(auc_only_cf)\n",
    "                total_auc.append(auc_lr_cf) \n",
    "                total_f1_cf.append(f1_only_cf)\n",
    "                total_f1.append(f1_lr_cf)\n",
    "\n",
    "                # Saving the model performance metrics of each iteration\n",
    "                model_perf_metrics_merged_only_for_cfs = model_perf_metrics_merged_only_for_cfs.append(model_perf_metric_lr_only_cf, ignore_index=True)\n",
    "                model_perf_metrics_merged = model_perf_metrics_merged.append(model_perf_metric_lr_cf, ignore_index=True)\n",
    "\n",
    "            else:\n",
    "            # Calculate means and standard deviations of auc and f1 scores of the iteration\n",
    "                total_auc_only_cf_mean = np.mean(total_auc_cf)\n",
    "                total_f1_only_cf_mean = np.mean(total_f1_cf)\n",
    "                total_auc_mean = np.mean(total_auc)\n",
    "                total_f1_mean = np.mean(total_f1)\n",
    "\n",
    "                total_auc_only_cf_std = round(np.std(total_auc_cf),8)\n",
    "                total_f1_only_cf_std = round(np.std(total_f1_cf),8)\n",
    "                total_auc_std = round(np.std(total_auc),8)\n",
    "                total_f1_std = round(np.std(total_f1),8)\n",
    "\n",
    "                # Creating new rows to save the model performance metrics of each sample size and CF number combination's all iterations\n",
    "                new_row_cf= {'Model': 'LR_avg_of_{}_iterations_only_cfs_of_sample:{}_cf:{}'.format(k, j, i) , 'Iteration': k, 'Sample Size': j, 'CF Num': i, 'Total CF Num':j*i , 'Precision (%)': '', 'F1 (%)': '','AUC(%)': '','F1_average(%)': total_f1_only_cf_mean, 'F1_std(%)': total_f1_only_cf_std, 'AUC_average(%)' :total_auc_only_cf_mean, 'AUC_std(%)': total_auc_only_cf_std}\n",
    "                new_row = {'Model': 'LR_avg_of_{}_iterations_sample:{}_cf:{}'.format(k, j, i), 'Iteration': k, 'Sample Size': j, 'CF Num': i, 'Total CF Num':j*i , 'Precision (%)': '', 'F1 (%)': '','AUC(%)': '','F1_average(%)': total_f1_mean, 'F1_std(%)':total_f1_std, 'AUC_average(%)' :total_auc_mean, 'AUC_std(%)': total_auc_std}\n",
    "                \n",
    "                # Saving these new rows to the model performance metrics dataframes    \n",
    "                model_perf_metrics_merged_only_for_cfs = model_perf_metrics_merged_only_for_cfs.append(new_row_cf, ignore_index=True)\n",
    "                model_perf_metrics_merged = model_perf_metrics_merged.append(new_row, ignore_index=True)\n",
    "    # Saving the model performance metrics dataframes as excel files after all the experiments are done.\n",
    "    model_perf_metrics_merged_only_for_cfs.to_excel('model_perf_metrics_merged_only_with_cfs_{}.xlsx'.format(num))\n",
    "    model_perf_metrics_merged.to_excel('model_perf_metrics_merged_{}.xlsx'.format(num))\n",
    "    \n",
    "    return  model_perf_metrics_merged_only_for_cfs, model_perf_metrics_merged  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns' categories\n",
    "numerical = ['age' ,'fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "categorical = ['workclass','marital-status',  'relationship', 'race', 'sex']\n",
    "continuous_features = ['capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:05<00:00,  1.88it/s]\n",
      "C:\\Users\\dideu\\AppData\\Local\\Temp\\ipykernel_21648\\4037314814.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_perf_metrics_merged_only_for_cfs = model_perf_metrics_merged_only_for_cfs.append(model_perf_metric_lr_only_cf, ignore_index=True)\n",
      "C:\\Users\\dideu\\AppData\\Local\\Temp\\ipykernel_21648\\4037314814.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_perf_metrics_merged = model_perf_metrics_merged.append(model_perf_metric_lr_cf, ignore_index=True)\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.84it/s]\n",
      "C:\\Users\\dideu\\AppData\\Local\\Temp\\ipykernel_21648\\4037314814.py:40: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_perf_metrics_merged_only_for_cfs = model_perf_metrics_merged_only_for_cfs.append(model_perf_metric_lr_only_cf, ignore_index=True)\n",
      "C:\\Users\\dideu\\AppData\\Local\\Temp\\ipykernel_21648\\4037314814.py:41: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  model_perf_metrics_merged = model_perf_metrics_merged.append(model_perf_metric_lr_cf, ignore_index=True)\n",
      "100%|██████████| 10/10 [00:05<00:00,  1.91it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 8\u001b[0m\n\u001b[0;32m      5\u001b[0m iteration_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m30\u001b[39m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Running the experiment\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m model_perf_metrics_merged_only_for_cfs, model_perf_metrics_merged \u001b[38;5;241m=\u001b[39m \u001b[43mrunning_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontinuous_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_size_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_CFs_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miteration_num\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfea_to_vary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[25], line 30\u001b[0m, in \u001b[0;36mrunning_exp\u001b[1;34m(X_fit, y_fit, continuous_features, sample_size_list, total_CFs_list, iteration_num, fea_to_vary, num)\u001b[0m\n\u001b[0;32m     27\u001b[0m new_y_fit \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([y_fit, y_fit_cf])\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Running the Logistic Regression model on the CFs dataset and the dataset with original X_fit plus CFs.\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m model_perf_metric_lr_only_cf, auc_only_cf, f1_only_cf \u001b[38;5;241m=\u001b[39m \u001b[43mrun_LR\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_fit_cf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_fit_cf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m_\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_iterations_sample:\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m_cf:\u001b[39;49m\u001b[38;5;132;43;01m{}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m model_perf_metric_lr_cf, auc_lr_cf, f1_lr_cf \u001b[38;5;241m=\u001b[39m run_LR(new_X_fit, new_y_fit, X_test, y_test, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_iterations_sample:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m_cf:\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(k, j, i), i , j , k)\n\u001b[0;32m     33\u001b[0m \u001b[38;5;66;03m# Appending the auc and f1 scores of each iteration to the lists, doing the same for only CFs set.\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[22], line 22\u001b[0m, in \u001b[0;36mrun_LR\u001b[1;34m(X_fit, y_fit, X_test, y_test, model_name, i, j, k)\u001b[0m\n\u001b[0;32m     20\u001b[0m model_LR \u001b[38;5;241m=\u001b[39m clf_LR\u001b[38;5;241m.\u001b[39mfit(X_fit, y_fit)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# Predict on the test dataset\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m y_pred_lr \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_LR\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Calculate the needed model performance metrics\u001b[39;00m\n\u001b[0;32m     24\u001b[0m precision_lr \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred_lr)\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **predict_params)\u001b[0m\n\u001b[0;32m    512\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:827\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    823\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m    824\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m    825\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 827\u001b[0m Xs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    828\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    829\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    830\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_transform_one\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfitted\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumn_as_strings\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfit_dataframe_and_transform_dataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_output(Xs)\n\u001b[0;32m    836\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Xs:\n\u001b[0;32m    837\u001b[0m     \u001b[38;5;66;03m# All transformers are None\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\compose\\_column_transformer.py:681\u001b[0m, in \u001b[0;36mColumnTransformer._fit_transform\u001b[1;34m(self, X, y, func, fitted, column_as_strings)\u001b[0m\n\u001b[0;32m    675\u001b[0m transformers \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m    676\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(\n\u001b[0;32m    677\u001b[0m         fitted\u001b[38;5;241m=\u001b[39mfitted, replace_strings\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, column_as_strings\u001b[38;5;241m=\u001b[39mcolumn_as_strings\n\u001b[0;32m    678\u001b[0m     )\n\u001b[0;32m    679\u001b[0m )\n\u001b[0;32m    680\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 681\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    682\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfitted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    684\u001b[0m \u001b[43m            \u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_safe_indexing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    685\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    686\u001b[0m \u001b[43m            \u001b[49m\u001b[43mweight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    687\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage_clsname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mColumnTransformer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    688\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_log_message\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    689\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    690\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtransformers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    691\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    692\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    693\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected 2D array, got 1D array instead\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\pipeline.py:940\u001b[0m, in \u001b[0;36m_transform_one\u001b[1;34m(transformer, X, y, weight, **fit_params)\u001b[0m\n\u001b[0;32m    939\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_transform_one\u001b[39m(transformer, X, y, weight, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params):\n\u001b[1;32m--> 940\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;66;03m# if we have a weight for this transformer, multiply output\u001b[39;00m\n\u001b[0;32m    942\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\pipeline.py:696\u001b[0m, in \u001b[0;36mPipeline.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    694\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[0;32m    695\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, _, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter():\n\u001b[1;32m--> 696\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Xt\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\utils\\_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    163\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1027\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1022\u001b[0m \u001b[38;5;66;03m# validation of X happens in _check_X called by _transform\u001b[39;00m\n\u001b[0;32m   1023\u001b[0m warn_on_unknown \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_unknown \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[0;32m   1024\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1025\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfrequent_if_exist\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1026\u001b[0m }\n\u001b[1;32m-> 1027\u001b[0m X_int, X_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhandle_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwarn_on_unknown\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1034\u001b[0m n_samples, n_features \u001b[38;5;241m=\u001b[39m X_int\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m   1036\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_drop_idx_after_grouping \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\dideu\\anaconda3\\envs\\banana\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:186\u001b[0m, in \u001b[0;36m_BaseEncoder._transform\u001b[1;34m(self, X, handle_unknown, force_all_finite, warn_on_unknown, ignore_category_indices)\u001b[0m\n\u001b[0;32m    183\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_feature_names(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_n_features(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m--> 186\u001b[0m X_int \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_samples\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_features\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    187\u001b[0m X_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mones((n_samples, n_features), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m    189\u001b[0m columns_with_unknown \u001b[38;5;241m=\u001b[39m []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Defining the experiment's features to vary, sample size, total CF number for sample and iteration number\n",
    "fea_to_vary = ['age', 'workclass', 'education-num', 'marital-status', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "sample_size_list = [10, 20, 30, 40, 50, 60]\n",
    "total_CFs_list = [1, 2, 3, 4, 5]\n",
    "iteration_num = 30\n",
    "\n",
    "# Running the experiment\n",
    "model_perf_metrics_merged_only_for_cfs, model_perf_metrics_merged = running_exp(X_fit, y_fit, continuous_features, sample_size_list, total_CFs_list, iteration_num, fea_to_vary, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
