{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries and Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataframe from a csv file\n",
    "df = pd.read_csv('CensusAdultIncome.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring the Data Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education  education-num  \\\n",
       "0   39         State-gov   77516  Bachelors             13   \n",
       "1   50  Self-emp-not-inc   83311  Bachelors             13   \n",
       "2   38           Private  215646    HS-grad              9   \n",
       "3   53           Private  234721       11th              7   \n",
       "4   28           Private  338409  Bachelors             13   \n",
       "\n",
       "       marital-status         occupation   relationship   race     sex  \\\n",
       "0       Never-married       Adm-clerical  Not-in-family  White    Male   \n",
       "1  Married-civ-spouse    Exec-managerial        Husband  White    Male   \n",
       "2            Divorced  Handlers-cleaners  Not-in-family  White    Male   \n",
       "3  Married-civ-spouse  Handlers-cleaners        Husband  Black    Male   \n",
       "4  Married-civ-spouse     Prof-specialty           Wife  Black  Female   \n",
       "\n",
       "   capital-gain  capital-loss  hours-per-week native-country income  \n",
       "0          2174             0              40  United-States  <=50K  \n",
       "1             0             0              13  United-States  <=50K  \n",
       "2             0             0              40  United-States  <=50K  \n",
       "3             0             0              40  United-States  <=50K  \n",
       "4             0             0              40           Cuba  <=50K  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  object\n",
      "dtypes: int64(6), object(9)\n",
      "memory usage: 5.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- workclass: A categorical feature representing the type of income, such as private, self-employment, and government employment. Some missing values present.\n",
    "- fnlwgt: An integer feature with no description provided. No missing values.\n",
    "- education: A categorical feature representing the level of education \n",
    "- education-num: An integer feature representing the numerical encoding of **education** level.\n",
    "- occupation: A categorical feature representing the type of occupation, such as managerial, technical, and service-related occupations. Some missing values present.\n",
    "- native-country: A categorical feature representing the country of origin, including various countries such as the United States, Canada, and India. Some missing values present.\n",
    "- income: The target variable, a binary feature representing income level, with categories >50K and <=50K. No missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Cleaning the target variable and making it binary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Target value has values with dots, therefore 4 catagories\n",
    "df['income'] = df['income'].str.replace('.', '')\n",
    "\n",
    "# Replace the values in the target column with string '0' and '1'.\n",
    "df['income'] = df['income'].str.replace('<=50K', '0')  \n",
    "df['income'] = df['income'].str.replace('>50K', '1')   \n",
    "\n",
    "# Convert to integer\n",
    "df['income'] = df['income'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 48842 entries, 0 to 48841\n",
      "Data columns (total 15 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             48842 non-null  int64 \n",
      " 1   workclass       47879 non-null  object\n",
      " 2   fnlwgt          48842 non-null  int64 \n",
      " 3   education       48842 non-null  object\n",
      " 4   education-num   48842 non-null  int64 \n",
      " 5   marital-status  48842 non-null  object\n",
      " 6   occupation      47876 non-null  object\n",
      " 7   relationship    48842 non-null  object\n",
      " 8   race            48842 non-null  object\n",
      " 9   sex             48842 non-null  object\n",
      " 10  capital-gain    48842 non-null  int64 \n",
      " 11  capital-loss    48842 non-null  int64 \n",
      " 12  hours-per-week  48842 non-null  int64 \n",
      " 13  native-country  48568 non-null  object\n",
      " 14  income          48842 non-null  int32 \n",
      "dtypes: int32(1), int64(6), object(8)\n",
      "memory usage: 5.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print count and percentage of classes variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " 0    37155\n",
      "1    11687\n",
      "Name: income, dtype: int64 \n",
      "\n",
      "Percentage of each class: \n",
      " 0    76.071823\n",
      "1    23.928177\n",
      "Name: income, dtype: float64\n",
      "\n",
      "Total number of rows:  48842\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts of unique values in the 'class' column \n",
    "class_counts = df['income'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each unique value in the 'class' column by dividing 'class_counts' by its sum and then multiplying by 100.\n",
    "class_percentages = class_counts / class_counts.sum() * 100\n",
    "\n",
    "print('Class counts:\\n' ,class_counts, '\\n')\n",
    "print('Percentage of each class: \\n' ,class_percentages)\n",
    "print('\\nTotal number of rows: ', df.shape[0])\n",
    "\n",
    "# Saving this for future use\n",
    "a = df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Droping nan values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some values are like '?'. Replacing them as NaN \n",
    "df[df == '?'] = np.nan\n",
    "# Dropping the rows with NaN values in  'workclass', 'occupation', 'native-country' for the test dataset\n",
    "df.dropna(subset=['workclass', 'occupation', 'native-country'], inplace=True)\n",
    "df.dropna( inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking wheter Education and Education-number are similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HS-grad         14783\n",
      "Some-college     9899\n",
      "Bachelors        7570\n",
      "Masters          2514\n",
      "Assoc-voc        1959\n",
      "Name: education, dtype: int64\n",
      "\n",
      "9     14783\n",
      "10     9899\n",
      "13     7570\n",
      "14     2514\n",
      "11     1959\n",
      "Name: education-num, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['education'].value_counts().head())\n",
    "print()\n",
    "print(df['education-num'].value_counts().head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From X set, education column is dropped as it is same with Education-num, which is already in numerical form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['education'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age         workclass  fnlwgt  education-num      marital-status  \\\n",
       "0   39         State-gov   77516             13       Never-married   \n",
       "1   50  Self-emp-not-inc   83311             13  Married-civ-spouse   \n",
       "2   38           Private  215646              9            Divorced   \n",
       "3   53           Private  234721              7  Married-civ-spouse   \n",
       "4   28           Private  338409             13  Married-civ-spouse   \n",
       "\n",
       "          occupation   relationship   race     sex  capital-gain  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male          2174   \n",
       "1    Exec-managerial        Husband  White    Male             0   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male             0   \n",
       "3  Handlers-cleaners        Husband  Black    Male             0   \n",
       "4     Prof-specialty           Wife  Black  Female             0   \n",
       "\n",
       "   capital-loss  hours-per-week native-country  income  \n",
       "0             0              40  United-States       0  \n",
       "1             0              13  United-States       0  \n",
       "2             0              40  United-States       0  \n",
       "3             0              40  United-States       0  \n",
       "4             0              40           Cuba       0  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count and percentage of Target classes values after droping NaN values \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class counts:\n",
      " 0    34014\n",
      "1    11208\n",
      "Name: income, dtype: int64 \n",
      "\n",
      "Percentage of each class: \n",
      " 0    75.215603\n",
      "1    24.784397\n",
      "Name: income, dtype: float64\n",
      "\n",
      "Number of rows after dropping NaN:  45222\n",
      "number of rows dropped:  3620\n"
     ]
    }
   ],
   "source": [
    "# Calculate the counts of unique values in the 'class' column of 'df_class_feature' and store it in 'class_counts'.\n",
    "class_counts = df['income'].value_counts()\n",
    "\n",
    "# Calculate the percentage of each unique value in the 'class' column by dividing 'class_counts' by its sum and then multiplying by 100.\n",
    "class_percentages = class_counts / class_counts.sum() * 100\n",
    "\n",
    "print('Class counts:\\n' ,class_counts, '\\n')\n",
    "print('Percentage of each class: \\n' ,class_percentages)\n",
    "\n",
    "b = df.shape[0]\n",
    "print('\\nNumber of rows after dropping NaN: ', b)\n",
    "print('number of rows dropped: ', a-b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Split data into separate fitting and test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating X and y sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating X and y sets.income is the target variable and native country dropped because it has 41 unique values and occupation is very similar too workclass.\n",
    "X = df.drop(['income', 'native-country', 'occupation'], axis=1)\n",
    "y = df['income']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the dataset into fitting data (60%) and test set (40%), the reason I chose 60 to 40 split is to have a bigger test set. I did some experiments with other ratios such as 70 to 30 and 80 to 20 and the model performance metrics were almost the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fit, X_test, y_fit, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The percentage of each class in the target variable for each set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined a function to calculate  and print the percentage of each class in the target variable\n",
    "def calculate_class_percentage(y):\n",
    "    class_percentage = {}\n",
    "    total_samples = len(y)\n",
    "    unique_classes = set(y)\n",
    "    \n",
    "    for cls in unique_classes:\n",
    "        class_count = sum(y == cls)\n",
    "        percentage = (class_count / total_samples) * 100\n",
    "        class_percentage[cls] = percentage\n",
    "    \n",
    "    return class_percentage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fit set class percentages:\n",
      "{0: 75.25522426565438, 1: 24.74477573434563}\n",
      "\n",
      "Test set class percentages:\n",
      "{0: 75.15617225938416, 1: 24.843827740615843}\n",
      "\n",
      " Number of rows of X fit 27133 \n",
      " Number of rows of X test 18089 \n",
      " Number of rows of Y fit 27133 \n",
      " Number of rows of y test 18089\n"
     ]
    }
   ],
   "source": [
    "# Calculate class percentages for each dataset\n",
    "fit_class_percentage = calculate_class_percentage(y_fit)\n",
    "test_class_percentage = calculate_class_percentage(y_test)\n",
    "\n",
    "# Print class percentages for each dataset\n",
    "print(\"Fit set class percentages:\")\n",
    "print(fit_class_percentage )\n",
    "print(\"\\nTest set class percentages:\")\n",
    "print(test_class_percentage)\n",
    "print('\\n Number of rows of X fit', X_fit.shape[0], '\\n Number of rows of X test', X_test.shape[0],'\\n Number of rows of Y fit', y_fit.shape[0],'\\n Number of rows of y test', y_test.shape[0],)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Random Forest and Logistig Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn imports\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# DiCE imports\n",
    "import dice_ml\n",
    "from dice_ml.utils import helpers  # helper functions\n",
    "\n",
    "import pickle\n",
    "from sklearn.metrics import accuracy_score,  recall_score, precision_score, f1_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Random Forest model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_RF (X_fit, y_fit, X_test, y_test, model_name):\n",
    "    \n",
    "    # Preprocessing for cataegorical data - OneHotEncoding\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Bundle preprocessing for data\n",
    "    transformations = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('cat', categorical_transformer, categorical)],\n",
    "        remainder='passthrough')\n",
    "    \n",
    "    # Define the Random Forest model\n",
    "    clf_RF = Pipeline(steps=[('preprocessor', transformations), ('classifier', RandomForestClassifier())])\n",
    "    # Run the random forest model\n",
    "    model_RF = clf_RF.fit(X_fit, y_fit)\n",
    "    # Predict on the test dataset\n",
    "    y_pred_rf = model_RF.predict(X_test)\n",
    "    # Calculate the needed model performance metrics\n",
    "    f1_rf = f1_score(y_test, y_pred_rf)\n",
    "    roc_rf = roc_auc_score(y_test, y_pred_rf)\n",
    "    a = len(X_fit)\n",
    "    # Saving the model performance metrics\n",
    "    models_rf = [('RF {}'.format(model_name), 0, 0, 0, a, f1_rf, roc_rf, 0, 0)]\n",
    "    # Saving the model performance metrics in a dataframe\n",
    "    model_perf_metrics_rf = pd.DataFrame(models_rf, columns = ['Model', 'Iteration', 'Sample Size', 'CF Num', 'X_fit Size',  'F1 (%)', 'AUC (%)', 'F1_std(%)', 'AUC_std(%)'])\n",
    "        \n",
    "    return model_RF, model_perf_metrics_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining Logistic Regression model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_LR(X_fit, y_fit, X_test, y_test, model_name, i, j , k):\n",
    "    # Preprocessing for categorical data - OneHotEncoding\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n",
    "\n",
    "    # Preprocessing for numerical data - StandardScaler\n",
    "    #numerical_transformer = Pipeline(steps=[\n",
    "        #('scaler', StandardScaler())])\n",
    "\n",
    "    # Bundle preprocessing for numerical and categorical data\n",
    "    transformations = ColumnTransformer(\n",
    "        transformers=[\n",
    "            #('num', numerical_transformer, numerical),  \n",
    "            ('cat', categorical_transformer, categorical)], \n",
    "        remainder='passthrough')\n",
    "\n",
    "    # Define the Logistic Regression model\n",
    "    clf_LR = Pipeline(steps=[('preprocessor', transformations), ('classifier', LogisticRegression(max_iter=1000))])\n",
    "    # Run the Logistic Regression model\n",
    "    model_LR = clf_LR.fit(X_fit, y_fit)\n",
    "    # Predict on the test dataset\n",
    "    y_pred_lr = model_LR.predict(X_test)\n",
    "    # Calculate the needed model performance metrics\n",
    "    f1_lr = f1_score(y_test, y_pred_lr)\n",
    "    roc_lr = roc_auc_score(y_test, y_pred_lr)\n",
    "    a = len(X_fit)\n",
    "\n",
    "    # Saving the model performance metrics\n",
    "    models_lr = [('LR {}'.format(model_name), k, j, i, a, f1_lr, roc_lr, 0, 0)]\n",
    "    # Saving the model performance metrics in a dataframe\n",
    "    model_perf_metric_lr = pd.DataFrame(models_lr, columns = ['Model', 'Iteration', 'Sample Size', 'CF Num','X_fit Size', 'F1 (%)', 'AUC (%)', 'F1_std(%)', 'AUC_std(%)'])\n",
    "\n",
    "    return  model_perf_metric_lr, roc_lr, f1_lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distrubution_plot(df, name, p):\n",
    "    lr_line = df[df['Model'] == 'LR default'][name].iloc[0]\n",
    "    rf_line = df[df['Model'] == 'RF default'][name].iloc[0]\n",
    "    df = df[(df['Model'] != 'RF default') & (df['Model'] != 'LR default')]\n",
    "        \n",
    "    x = df['Sample Size'].unique()\n",
    "    x_2 = df['CF Num'].unique()\n",
    "    x_3 = df['Iteration'].unique()\n",
    "\n",
    "    y = df[name]\n",
    "\n",
    "    # combine x and x_2 for x-axis labels\n",
    "    combined_x = [f\"{i}-{j}-{k}\" for i in x for j in x_2 for k in x_3]\n",
    "\n",
    "    # plot lines\n",
    "    plt.figure(figsize=(20,10))\n",
    "    plt.plot(combined_x, y, label=\"{} Values\".format(name))\n",
    "    plt.axhline(y=lr_line, color='r', linestyle='--', label=\"default_lr_line\")  # Plot lr_line as a horizontal line\n",
    "    #plt.axhline(y=rf_line, color='green', linestyle='--', label=\"default_rf_line\")  # Plot lr_line as a horizontal line\n",
    "    if p is True:\n",
    "        plt.title('Distribution of {} score, average of iterations'.format(name))\n",
    "        plt.savefig(f\"Distribution_of_{name}_score_avg.svg\", format='svg')\n",
    "    else:    \n",
    "        plt.title('Distribution of {} score'.format(name))\n",
    "        plt.savefig(f\"Distribution_of_{name}_score.svg\", format='svg')\n",
    "\n",
    "    plt.xlabel('Sample Size- CF Num- Iteration')\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.xticks(rotation=40)  # rotate x-axis labels for better visibility\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Counterfactuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 27133 entries, 23913 to 35636\n",
      "Data columns (total 11 columns):\n",
      " #   Column          Non-Null Count  Dtype \n",
      "---  ------          --------------  ----- \n",
      " 0   age             27133 non-null  int64 \n",
      " 1   workclass       27133 non-null  object\n",
      " 2   fnlwgt          27133 non-null  int64 \n",
      " 3   education-num   27133 non-null  int64 \n",
      " 4   marital-status  27133 non-null  object\n",
      " 5   relationship    27133 non-null  object\n",
      " 6   race            27133 non-null  object\n",
      " 7   sex             27133 non-null  object\n",
      " 8   capital-gain    27133 non-null  int64 \n",
      " 9   capital-loss    27133 non-null  int64 \n",
      " 10  hours-per-week  27133 non-null  int64 \n",
      "dtypes: int64(6), object(5)\n",
      "memory usage: 2.5+ MB\n"
     ]
    }
   ],
   "source": [
    "X_fit.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the DICE model. Possible adjustments that can be made are, \n",
    "- which model to use for CF generation, \n",
    "- continuous features, \n",
    "- size of the sample that will be used to create the CFs, \n",
    "- how many CFs to generate per one sample,\n",
    "- which features can vary in the CF generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining DICE model\n",
    "def generate_counterfactuals(X_fit, y_fit, model, continuous_features, sample_size, total_CFs, fea_to_vary, outcome_name):\n",
    "    \n",
    "    # Creating a Data object\n",
    "    d = dice_ml.Data(dataframe=X_fit.assign(income=y_fit), continuous_features=continuous_features, outcome_name=outcome_name)\n",
    "    # Creating a Model object\n",
    "    m = dice_ml.Model(model=model, backend=\"sklearn\")\n",
    "    # Creating the DICE model with data and model object \n",
    "    exp = dice_ml.Dice(d, m, method=\"random\")\n",
    "\n",
    "    # Execution of the DICE model to generate counterfactuals\n",
    "    e1 = exp.generate_counterfactuals(X_fit[0:sample_size], total_CFs=total_CFs, desired_class=\"opposite\", features_to_vary= fea_to_vary)\n",
    "    \n",
    "    # Comment out the below line as CFs needed to be visualized in the notebook\n",
    "    #e1.visualize_as_dataframe(show_only_changes=True)\n",
    "\n",
    "    # Creating a new empty dataframe to store the generated CFs\n",
    "    cf_df = pd.DataFrame()\n",
    "    # For loop to append the counterfactuals of each sample, to a dataframe\n",
    "    for i in range(0, sample_size):\n",
    "        # Saving CFs\n",
    "        xd = e1.cf_examples_list[i].final_cfs_df\n",
    "        # Adding the generated CFs to the empty dataframe\n",
    "        cf_df = pd.concat([cf_df, xd])\n",
    "# If the sample size is reached and the CFs are generated for all the samples, followiing code resets the index of the dataframe and saves the generated CFs as a csv file.\n",
    "    else:\n",
    "        # Resetting the index of the dataframe to not have duplicate index number\n",
    "        cf_df.reset_index(drop=True, inplace=True)\n",
    "        new_start_index = len(X_fit) + i + len(cf_df)\n",
    "        cf_df.index += new_start_index \n",
    "        # Saving the generated CFs as a csv file\n",
    "        cf_df.to_csv('cf_df_{}_{}.csv'.format(sample_size, total_CFs))\n",
    "        \n",
    "        # Following code creates X and y fit sets for the generated CFs and returns them for further use.\n",
    "        X_fit_cf = cf_df.drop([outcome_name], axis=1)\n",
    "        y_fit_cf = cf_df[outcome_name]\n",
    "\n",
    "    return X_fit_cf, y_fit_cf, cf_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a fuction that runs the RF and LR plus DICE model that generates counterfactuals. \n",
    "#### Then the function saves these CF explanations into a dataframe and trains the LR again with the generated CFs. At the same time, model appends the original fit-set to CF dataset and trains the LR again with the combined version of the datasets. For each model training, LR model function appends the new model performance metrics into a dataframe. Possible adjustments that can be made are, \n",
    "- continuous features, \n",
    "- size of the sample that will be used to create the CFs, \n",
    "- how many CFs to generate per one sample,\n",
    "- how many iterations will be made for each sample_size and CF_number pair,\n",
    "- which features can vary in the CF generation process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment running function\n",
    "def running_exp(X_fit, y_fit, continuous_features, sample_size_list, total_CFs_list, iteration_num, fea_to_vary, num, list_of_models):\n",
    "    #Running default Random Forest\n",
    "    model_RF, model_perf_metric_rf = run_RF(X_fit, y_fit, X_test, y_test, 'default')\n",
    "    #Running default Logistic Regression\n",
    "    model_perf_metric_lr, auc, f1 = run_LR(X_fit, y_fit, X_test, y_test, 'default', 1 , 0 , 0)\n",
    "\n",
    "    # Merging the default model performance metrics in a dataframe to accommodate new models, and doing it twice to use the second one on only CFs dataset.\n",
    "    model_perf_metrics_merged = model_perf_metric_rf.merge(model_perf_metric_lr, how='outer')\n",
    "    model_perf_metrics_merged_only_for_cfs = model_perf_metric_rf.merge(model_perf_metric_lr, how='outer')\n",
    "    model_perf_metrics_average_of_iterations  = model_perf_metric_rf.merge(model_perf_metric_lr, how='outer')\n",
    "    \n",
    "    # Loop through different sample sizes\n",
    "    for j in sample_size_list:\n",
    "        # Loop through different total CF numbers\n",
    "        for i in total_CFs_list:\n",
    "            # Initializing empty lists for saving auc and f1 scores for each iteration\n",
    "            total_auc = []\n",
    "            total_f1 = []\n",
    "            total_auc_cf = []\n",
    "            total_f1_cf = []\n",
    "            # Loop through iteration numbers, doing a new experiment for each sample_size and CF_number combination\n",
    "            for k in range(1,iteration_num+1):    \n",
    "                # Generating counterfactuals using the 'generate_counterfactuals' function\n",
    "                X_fit_cf, y_fit_cf, cf_df = generate_counterfactuals(X_fit, y_fit, model_RF, continuous_features, j, i, fea_to_vary, 'income')\n",
    "                # Concatenating the original dataset with the generated CFs dataset\n",
    "                new_cf_df = pd.DataFrame()\n",
    "                new_cf_df = new_cf_df.append(cf_df)\n",
    "                new_X_fit = pd.concat([X_fit, X_fit_cf])\n",
    "                new_y_fit = pd.concat([y_fit, y_fit_cf])\n",
    "\n",
    "                # Running the Logistic Regression model on the CFs dataset and the dataset with original X_fit plus CFs.\n",
    "                model_perf_metric_lr_only_cf, auc_only_cf, f1_only_cf = run_LR(X_fit_cf, y_fit_cf, X_test, y_test, '_{}_iterations_sample:{}_cf:{}'.format(k, j, i), i , j , k)\n",
    "                model_perf_metric_lr_cf, auc_lr_cf, f1_lr_cf = run_LR(new_X_fit, new_y_fit, X_test, y_test, '_{}_iterations_sample:{}_cf:{}'.format(k, j, i), i , j , k)\n",
    "                \n",
    "                # Appending the auc and f1 scores of each iteration to the lists, doing the same for only CFs set.\n",
    "                total_auc_cf.append(auc_only_cf)\n",
    "                total_auc.append(auc_lr_cf) \n",
    "                total_f1_cf.append(f1_only_cf)\n",
    "                total_f1.append(f1_lr_cf)\n",
    "\n",
    "                # Saving the model performance metrics of each iteration\n",
    "                model_perf_metrics_merged_only_for_cfs = model_perf_metrics_merged_only_for_cfs.append(model_perf_metric_lr_only_cf, ignore_index=True)\n",
    "                model_perf_metrics_merged = model_perf_metrics_merged.append(model_perf_metric_lr_cf, ignore_index=True)\n",
    "                \n",
    "            else:\n",
    "            # Calculate means and standard deviations of auc and f1 scores of all the iterations for each sample size and CF number combination\n",
    "                total_auc_only_cf_mean = np.mean(total_auc_cf)\n",
    "                total_f1_only_cf_mean = np.mean(total_f1_cf)\n",
    "                total_auc_mean = np.mean(total_auc)\n",
    "                total_f1_mean = np.mean(total_f1)\n",
    "\n",
    "                total_auc_only_cf_std = round(np.std(total_auc_cf),8)\n",
    "                total_f1_only_cf_std = round(np.std(total_f1_cf),8)\n",
    "                total_auc_std = round(np.std(total_auc),8)\n",
    "                total_f1_std = round(np.std(total_f1),8)\n",
    "                a = len(new_X_fit)\n",
    "                b = len(X_fit_cf)\n",
    "                # Creating new rows to save the model performance metrics of each sample size and CF number combination's all iterations\n",
    "                new_row_cf= {'Model': 'LR_avg_of_{}_iterations_sample:{}_cf:{}_only_cf'.format(k, j, i) , 'Iteration': k, 'Sample Size': j, 'CF Num': i, 'X_fit Size':b , 'F1 (%)': total_f1_only_cf_mean, 'F1_std(%)': total_f1_only_cf_std, 'AUC (%)' :total_auc_only_cf_mean, 'AUC_std(%)': total_auc_only_cf_std}\n",
    "                new_row = {'Model': 'LR_avg_of_{}_iterations_sample:{}_cf:{}'.format(k, j, i), 'Iteration': k, 'Sample Size': j, 'CF Num': i, 'X_fit Size':a ,'F1 (%)': total_f1_mean, 'F1_std(%)':total_f1_std, 'AUC (%)' :total_auc_mean, 'AUC_std(%)': total_auc_std}\n",
    "                \n",
    "                # Saving these new rows to the model performance metrics dataframes    \n",
    "                model_perf_metrics_average_of_iterations = model_perf_metrics_average_of_iterations.append(new_row, ignore_index=True)\n",
    "                \n",
    "    # Saving the model performance metrics dataframes as excel files after all the experiments are done.\n",
    "    model_perf_metrics_merged_only_for_cfs.to_excel('model_perf_metrics_merged_only_with_cfs_{}.xlsx'.format(num))\n",
    "    model_perf_metrics_merged.to_excel('model_perf_metrics_merged_{}.xlsx'.format(num))\n",
    "    model_perf_metrics_average_of_iterations.to_excel('model_perf_metrics_average_of_iterations_{}.xlsx'.format(num))\n",
    "    \n",
    "    for q in list_of_models:\n",
    "        distrubution_plot(model_perf_metrics_average_of_iterations, q, True )\n",
    "        distrubution_plot(model_perf_metrics_merged, q, False )\n",
    "        \n",
    "    return  model_perf_metrics_merged_only_for_cfs, model_perf_metrics_merged, new_cf_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the columns' categories\n",
    "numerical = ['age' ,'fnlwgt','education-num','capital-gain','capital-loss','hours-per-week']\n",
    "categorical = ['workclass','marital-status',  'relationship', 'race', 'sex']\n",
    "continuous_features = ['capital-gain', 'capital-loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the experiment's features to vary, sample size, total CF number for sample and iteration number\n",
    "fea_to_vary = ['age', 'workclass', 'education-num', 'marital-status', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "sample_size_list = [50, 100]\n",
    "total_CFs_list = [2, 5]\n",
    "iteration_num = 5\n",
    "list_azxkdkd = ['F1 (%)', 'AUC (%)']\n",
    "\n",
    "# Running the experiment\n",
    "model_perf_metrics_merged_only_for_cfs, model_perf_metrics_merged, neww = running_exp(X_fit, y_fit, continuous_features, sample_size_list, total_CFs_list, iteration_num, fea_to_vary, 'ammm', list_azxkdkd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "banana",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
